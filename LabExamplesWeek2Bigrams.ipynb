{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting started to process a text example\n",
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191673\n",
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book Emma from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file0 = nltk.corpus.gutenberg.fileids( ) [0]\n",
    "emmatext = nltk.corpus.gutenberg.raw(file0)\n",
    "emmatokens = nltk.word_tokenize(emmatext) \n",
    "emmawords = [w.lower( ) for w in emmatokens] \n",
    "print(len(emmawords))\n",
    "print(emmawords[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191673\n",
      "192427\n"
     ]
    }
   ],
   "source": [
    "# digression to show alternate tokenization taken from the corpus words function\n",
    "emmawords2 = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "emmawords2lowercase = [w.lower() for w in emmawords2]\n",
    "print(len(emmawords))\n",
    "print(len(emmawords2lowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an']\n",
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'\", 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have']\n"
     ]
    }
   ],
   "source": [
    "print(emmawords[:110])\n",
    "print(emmawords2lowercase[:110])\n",
    "# end of digression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 12016\n",
      ". \t 6355\n",
      "the \t 5198\n",
      "to \t 5179\n",
      "and \t 4875\n",
      "of \t 4284\n",
      "i \t 3164\n",
      "a \t 3124\n",
      "-- \t 3100\n",
      "it \t 2500\n",
      "'' \t 2452\n",
      "her \t 2448\n",
      "was \t 2396\n",
      "; \t 2353\n",
      "she \t 2336\n",
      "not \t 2279\n",
      "in \t 2173\n",
      "be \t 1970\n",
      "you \t 1962\n",
      "he \t 1806\n",
      "that \t 1804\n",
      "`` \t 1735\n",
      "had \t 1623\n",
      "but \t 1439\n",
      "as \t 1436\n",
      "for \t 1346\n",
      "have \t 1319\n",
      "is \t 1241\n",
      "with \t 1215\n",
      "very \t 1202\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(emmawords)\n",
    "nitems = ndist.most_common(30)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "# this regular expression pattern matches any word that contains all non-alphabetical\n",
    "#   lower-case characters [^a-z]+\n",
    "# the beginning ^ and ending $ require the match to begin and end on a word boundary \n",
    "pattern = re.compile('^[^a-z]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "# match the pattern on a text string with all special (non-alphabetical) characters\n",
    "nonAlphaMatch = pattern.match('**')\n",
    "#  if it matched, print a message\n",
    "if nonAlphaMatch: print ('matched non-alphabetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161456\n",
      "['emma', 'by', 'jane', 'austen', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses']\n"
     ]
    }
   ],
   "source": [
    "# apply the function to remove non-alphabetical words in emmawords\n",
    "alphaemmawords = [w for w in emmawords if not alpha_filter(w)]\n",
    "print(len(alphaemmawords))\n",
    "print(alphaemmawords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number stopwords: 153\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print('number stopwords:', len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the is a stopword!\n"
     ]
    }
   ],
   "source": [
    "# test if a word is in a list by using the Python keyword \"in\"\n",
    "word = 'the'\n",
    "if word in stopwords:\n",
    "    print (word + ' is a stopword!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74093\n"
     ]
    }
   ],
   "source": [
    "# further filter the words by leaving out any word in the stopwords\n",
    "stoppedemmawords = [w for w in alphaemmawords if not w in stopwords]\n",
    "print(len(stoppedemmawords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mr.', 1089)\n",
      "(\"'s\", 866)\n",
      "('emma', 855)\n",
      "('could', 836)\n",
      "('would', 818)\n",
      "('mrs.', 668)\n",
      "('miss', 597)\n",
      "('must', 566)\n",
      "('harriet', 496)\n",
      "('much', 484)\n",
      "('said', 483)\n",
      "('one', 447)\n",
      "('every', 434)\n",
      "('weston', 430)\n",
      "('thing', 394)\n",
      "('think', 383)\n",
      "('elton', 378)\n",
      "('well', 375)\n",
      "('knightley', 373)\n",
      "('little', 359)\n",
      "('never', 358)\n",
      "('know', 335)\n",
      "('might', 325)\n",
      "('good', 313)\n",
      "('say', 310)\n",
      "('woodhouse', 308)\n",
      "('jane', 299)\n",
      "('quite', 282)\n",
      "('time', 275)\n",
      "('great', 263)\n"
     ]
    }
   ],
   "source": [
    "# use this list for a betterfrequency distribution\n",
    "emmadist = FreqDist(stoppedemmawords)\n",
    "emmaitems = emmadist.most_common(30)\n",
    "for item in emmaitems:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'emma'), ('emma', 'by'), ('by', 'jane'), ('jane', 'austen'), ('austen', '1816'), ('1816', ']'), (']', 'volume'), ('volume', 'i'), ('i', 'chapter'), ('chapter', 'i'), ('i', 'emma'), ('emma', 'woodhouse'), ('woodhouse', ','), (',', 'handsome'), ('handsome', ','), (',', 'clever'), ('clever', ','), (',', 'and'), ('and', 'rich'), ('rich', ',')]\n"
     ]
    }
   ],
   "source": [
    "# look at some bigrams using the nltk.bigrams function\n",
    "emmabigrams = list(nltk.bigrams(emmawords))\n",
    "print(emmabigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'> ((',', 'and'), 0.00981880598728042)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first), first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.00981880598728042)\n",
      "(('.', \"''\"), 0.0060363222780464645)\n",
      "((\"''\", '``'), 0.005003312934007398)\n",
      "((';', 'and'), 0.004523328794352882)\n",
      "(('to', 'be'), 0.0031512002212100818)\n",
      "((',', \"''\"), 0.0030468558430243172)\n",
      "(('.', 'i'), 0.0029738147782942823)\n",
      "((',', 'i'), 0.0029685975593849944)\n",
      "(('of', 'the'), 0.002916425370292112)\n",
      "(('in', 'the'), 0.0023216624146332556)\n",
      "(('it', 'was'), 0.002306010757905391)\n",
      "((';', 'but'), 0.0022277524742660678)\n",
      "(('.', '``'), 0.0021703630662638974)\n",
      "(('.', 'she'), 0.002154711409536033)\n",
      "(('i', 'am'), 0.0020451498124409804)\n",
      "((',', 'that'), 0.0018781988073437574)\n",
      "(('!', '--'), 0.001794723304795146)\n",
      "(('--', 'and'), 0.0017425511157022637)\n",
      "(('she', 'had'), 0.0017321166778836872)\n",
      "(('she', 'was'), 0.0017112478022465346)\n",
      "(('had', 'been'), 0.001601686205151482)\n",
      "((',', 'she'), 0.0015860345484236173)\n",
      "((',', 'but'), 0.001580817329514329)\n",
      "(('.', 'he'), 0.001580817329514329)\n",
      "(('it', 'is'), 0.0015442967971493115)\n",
      "((',', 'as'), 0.0015234279215121586)\n",
      "(('i', 'have'), 0.0014660385135099885)\n",
      "(('could', 'not'), 0.0014503868567821237)\n",
      "(('mr.', 'knightley'), 0.0014138663244171062)\n",
      "(('.', 'it'), 0.0013877802298706652)\n"
     ]
    }
   ],
   "source": [
    "# scores are bigram frequencies normalized by dividing by the total number of bigrams\n",
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('to', 'be'), 0.0031512002212100818)\n",
      "(('of', 'the'), 0.002916425370292112)\n",
      "(('in', 'the'), 0.0023216624146332556)\n",
      "(('it', 'was'), 0.002306010757905391)\n",
      "(('i', 'am'), 0.0020451498124409804)\n",
      "(('she', 'had'), 0.0017321166778836872)\n",
      "(('she', 'was'), 0.0017112478022465346)\n",
      "(('had', 'been'), 0.001601686205151482)\n",
      "(('it', 'is'), 0.0015442967971493115)\n",
      "(('i', 'have'), 0.0014660385135099885)\n",
      "(('could', 'not'), 0.0014503868567821237)\n",
      "(('mr.', 'knightley'), 0.0014138663244171062)\n",
      "(('of', 'her'), 0.0013564769164149358)\n",
      "(('mrs.', 'weston'), 0.0012834358516849009)\n",
      "(('have', 'been'), 0.0012573497571384598)\n",
      "(('he', 'had'), 0.0012521325382291715)\n",
      "(('to', 'the'), 0.001236480881501307)\n",
      "(('do', 'not'), 0.0012208292247734424)\n",
      "(('and', 'the'), 0.00116865703568056)\n",
      "(('he', 'was'), 0.0011582225978619836)\n",
      "(('would', 'be'), 0.0011217020654969662)\n",
      "(('mr.', 'elton'), 0.0011008331898598133)\n",
      "(('such', 'a'), 0.0010434437818576429)\n",
      "(('a', 'very'), 0.0010330093440390664)\n",
      "(('of', 'his'), 0.0009912715927647608)\n",
      "(('that', 'she'), 0.0009599682793090315)\n",
      "(('to', 'have'), 0.0009599682793090315)\n",
      "(('to', 'her'), 0.0009599682793090315)\n",
      "(('did', 'not'), 0.0009547510603997434)\n",
      "(('and', 'i'), 0.0009443166225811669)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('mr.', 'knightley'), 0.0014138663244171062)\n",
      "(('mrs.', 'weston'), 0.0012834358516849009)\n",
      "(('mr.', 'elton'), 0.0011008331898598133)\n",
      "(('miss', 'woodhouse'), 0.0008764927767604201)\n",
      "(('mr.', 'weston'), 0.0008243205876675379)\n",
      "(('frank', 'churchill'), 0.000751279522937503)\n",
      "(('mrs.', 'elton'), 0.0007304106473003501)\n",
      "(('mr.', 'woodhouse'), 0.0006834556771167561)\n",
      "(('every', 'thing'), 0.0006469351447517387)\n",
      "(('miss', 'fairfax'), 0.0006365007069331622)\n",
      "(('miss', 'bates'), 0.0005791112989309918)\n",
      "(('every', 'body'), 0.0005686768611124154)\n",
      "(('jane', 'fairfax'), 0.0005425907665659743)\n",
      "(('harriet', \"'s\"), 0.0004486808261987865)\n",
      "(('young', 'man'), 0.0004330291694709218)\n",
      "(('emma', \"'s\"), 0.0003860741992873279)\n",
      "(('great', 'deal'), 0.0003339020101944457)\n",
      "(('elton', \"'s\"), 0.00032346757237586933)\n",
      "(('emma', 'could'), 0.0003182503534665811)\n",
      "(('said', 'emma'), 0.00030781591564800465)\n",
      "(('miss', 'smith'), 0.00029738147782942825)\n",
      "(('john', 'knightley'), 0.0002869470400108518)\n",
      "(('mrs.', 'goddard'), 0.0002712953832829872)\n",
      "(('dare', 'say'), 0.00026607816437369895)\n",
      "(('mr.', 'frank'), 0.00025564372655512255)\n",
      "(('miss', 'taylor'), 0.0002452092887365461)\n",
      "(('weston', \"'s\"), 0.00022955763200868144)\n",
      "(('mrs.', 'churchill'), 0.00020347153746224037)\n",
      "(('said', 'mr.'), 0.00019825431855295217)\n",
      "(('mr.', 'martin'), 0.00019303709964366394)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.00981880598728042)\n",
      "(('.', \"''\"), 0.0060363222780464645)\n",
      "((\"''\", '``'), 0.005003312934007398)\n",
      "((';', 'and'), 0.004523328794352882)\n",
      "(('to', 'be'), 0.0031512002212100818)\n",
      "((',', \"''\"), 0.0030468558430243172)\n",
      "(('.', 'i'), 0.0029738147782942823)\n",
      "((',', 'i'), 0.0029685975593849944)\n",
      "(('of', 'the'), 0.002916425370292112)\n",
      "(('in', 'the'), 0.0023216624146332556)\n",
      "(('it', 'was'), 0.002306010757905391)\n",
      "((';', 'but'), 0.0022277524742660678)\n",
      "(('.', '``'), 0.0021703630662638974)\n",
      "(('.', 'she'), 0.002154711409536033)\n",
      "(('i', 'am'), 0.0020451498124409804)\n",
      "((',', 'that'), 0.0018781988073437574)\n",
      "(('!', '--'), 0.001794723304795146)\n",
      "(('--', 'and'), 0.0017425511157022637)\n",
      "(('she', 'had'), 0.0017321166778836872)\n",
      "(('she', 'was'), 0.0017112478022465346)\n",
      "(('had', 'been'), 0.001601686205151482)\n",
      "((',', 'she'), 0.0015860345484236173)\n",
      "((',', 'but'), 0.001580817329514329)\n",
      "(('.', 'he'), 0.001580817329514329)\n",
      "(('it', 'is'), 0.0015442967971493115)\n",
      "((',', 'as'), 0.0015234279215121586)\n",
      "(('i', 'have'), 0.0014660385135099885)\n",
      "(('could', 'not'), 0.0014503868567821237)\n",
      "(('mr.', 'knightley'), 0.0014138663244171062)\n",
      "(('.', 'it'), 0.0013877802298706652)\n"
     ]
    }
   ],
   "source": [
    "# a filter to remove low frequency words\n",
    "finder2 = BigramCollocationFinder.from_words(emmawords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"''\", '``'), 0.005003312934007398)\n",
      "(('to', 'be'), 0.0031512002212100818)\n",
      "(('of', 'the'), 0.002916425370292112)\n",
      "(('in', 'the'), 0.0023216624146332556)\n",
      "(('it', 'was'), 0.002306010757905391)\n",
      "(('--', 'and'), 0.0017425511157022637)\n",
      "(('she', 'had'), 0.0017321166778836872)\n",
      "(('she', 'was'), 0.0017112478022465346)\n",
      "(('had', 'been'), 0.001601686205151482)\n",
      "(('it', 'is'), 0.0015442967971493115)\n",
      "(('could', 'not'), 0.0014503868567821237)\n",
      "(('mr.', 'knightley'), 0.0014138663244171062)\n",
      "((\"''\", 'said'), 0.0013825630109613768)\n",
      "(('``', 'i'), 0.0013616941353242241)\n",
      "(('of', 'her'), 0.0013564769164149358)\n",
      "(('--', 'i'), 0.0013408252596870712)\n",
      "(('mrs.', 'weston'), 0.0012834358516849009)\n",
      "(('have', 'been'), 0.0012573497571384598)\n",
      "(('he', 'had'), 0.0012521325382291715)\n",
      "(('to', 'the'), 0.001236480881501307)\n"
     ]
    }
   ],
   "source": [
    "# filters can be applied to both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('26th', 'ult.'), 17.54828760064729)\n",
      "(('_______', 'regiment'), 17.54828760064729)\n",
      "(('_a_', '_source_'), 17.54828760064729)\n",
      "(('_amor_', '_patriae_'), 17.54828760064729)\n",
      "(('_and_', '_misery_'), 17.54828760064729)\n",
      "(('_any_', '_thing_'), 17.54828760064729)\n",
      "(('_be_', '_a_'), 17.54828760064729)\n",
      "(('_caro_', '_sposo_'), 17.54828760064729)\n",
      "(('_dissolved_', '_it_.'), 17.54828760064729)\n",
      "(('_great_', '_way_'), 17.54828760064729)\n",
      "(('_most_', '_precious_'), 17.54828760064729)\n",
      "(('_precious_', '_treasures_'), 17.54828760064729)\n",
      "(('_repentance_', '_and_'), 17.54828760064729)\n",
      "(('_rev._', '_philip_'), 17.54828760064729)\n",
      "(('_robin_', '_adair_'), 17.54828760064729)\n",
      "(('_small_', 'half-glass'), 17.54828760064729)\n",
      "(('_with_', '_time_'), 17.54828760064729)\n",
      "(('`our', 'lot'), 17.54828760064729)\n",
      "(('adequate', 'restoratives'), 17.54828760064729)\n",
      "(('austen', '1816'), 17.54828760064729)\n",
      "(('baronne', \"d'almane\"), 17.54828760064729)\n",
      "(('base', 'aspersion'), 17.54828760064729)\n",
      "(('bulky', 'forms'), 17.54828760064729)\n",
      "(('christened', 'catherine'), 17.54828760064729)\n",
      "(('clear-sighted', 'goodwill.'), 17.54828760064729)\n",
      "(('coarser', 'featured'), 17.54828760064729)\n",
      "(('comtesse', \"d'ostalis\"), 17.54828760064729)\n",
      "(('dated', 'sept.'), 17.54828760064729)\n",
      "(('daughter-in-law', 'elect'), 17.54828760064729)\n",
      "(('de', 'genlis'), 17.54828760064729)\n"
     ]
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('d', \"'ye\"), 14.96332509992613)\n",
      "(('sore', 'throat'), 14.088855982009989)\n",
      "(('brunswick', 'square'), 13.951352458260054)\n",
      "(('william', 'larkins'), 13.08885598200999)\n",
      "(('baked', 'apples'), 12.96332509992613)\n",
      "(('box', 'hill'), 12.73521902739529)\n",
      "(('sixteen', 'miles'), 12.612827852841999)\n",
      "(('maple', 'grove'), 12.59409129026041)\n",
      "(('hair', 'cut'), 12.062860773477047)\n",
      "(('south', 'end'), 11.963325099926132)\n",
      "(('colonel', 'campbell'), 11.411391399592448)\n",
      "(('protest', 'against'), 11.346653739477636)\n",
      "(('robert', 'martin'), 11.093092974896459)\n",
      "(('five', 'couple'), 10.840928468566405)\n",
      "(('vast', 'deal'), 10.761691238756482)\n",
      "(('ready', 'wit'), 10.65145066970269)\n",
      "(('donwell', 'abbey'), 10.518540257253235)\n",
      "(('musical', 'society'), 10.508271921799409)\n",
      "(('infinitely', 'superior'), 10.229970759312303)\n",
      "(('married', 'women'), 10.056434504317613)\n",
      "(('five', 'minutes'), 10.031871251277801)\n",
      "(('three', 'months'), 9.96332509992613)\n",
      "(('years', 'ago'), 9.95666136964512)\n",
      "(('depend', 'upon'), 9.931738756868299)\n",
      "(('ten', 'minutes'), 9.866170835697215)\n",
      "(('sat', 'down'), 9.794513718794526)\n",
      "(('hurrying', 'away'), 9.602258611131811)\n",
      "(('few', 'moments'), 9.557332740250294)\n",
      "(('few', 'minutes'), 9.414374786408253)\n",
      "(('lovely', 'woman'), 9.410784076897352)\n"
     ]
    }
   ],
   "source": [
    "# first apply frequency filter of 5\n",
    "finder3.apply_freq_filter(5)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
